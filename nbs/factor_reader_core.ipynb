{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 核心功能\n",
    "\n",
    "> 读取因子数据的核心模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp __init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import deeplake\n",
    "from loguru import logger\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def __initialize_factor(\n",
    "    fac_key: str,\n",
    "    fac_df: pd.DataFrame,\n",
    "    token: str,\n",
    "    fac_name: str,\n",
    "    fac_report: str,\n",
    "    fac_wechat_link: str,\n",
    "):\n",
    "    \"\"\"请勿使用此函数\"\"\"\n",
    "    ds_object = deeplake.load(\"hub://chenzongwei/factor\", token=token)\n",
    "    ds_object.factors_list.append(\n",
    "        {\n",
    "            \"fac_key\": fac_key,\n",
    "            \"fac_name\": fac_name,\n",
    "            \"fac_report\": fac_report,\n",
    "            \"fac_wechat_link\": fac_wechat_link,\n",
    "        }\n",
    "    )\n",
    "    logger.success(f\"已经将代号为{fac_key}的{fac_name}因子的相关信息写入因子信息表\")\n",
    "    \"\"\"处理df数据的部分\"\"\"\n",
    "    fac_df.index = fac_df.index.strftime(\"%Y%m%d\").astype(int)\n",
    "    fac_df.columns = fac_df.columns.str.slice(start=0, stop=-3).astype(int)\n",
    "    fac_df = fac_df.stack().reset_index()\n",
    "    fac_df.columns = [\"date\", \"code\", \"fac\"]\n",
    "    dates = fac_df.iloc[:, 0]\n",
    "    dates = sorted(list(set(dates)))\n",
    "    \"\"\"创建新的group和tensor\"\"\"\n",
    "    ds_object.create_group(fac_key)\n",
    "    ds_object[fac_key].create_tensor(\"value\")\n",
    "    ds_object[fac_key].create_tensor(\"date\", htype=\"class_label\")\n",
    "    logger.success(\"已经成功创建新的group和tensor\")\n",
    "    \"\"\"每天写入\"\"\"\n",
    "    for date in tqdm.auto.tqdm(dates):\n",
    "        son = fac_df[fac_df.date == date].to_numpy()\n",
    "        ds_object[fac_key].append({\"value\": son, \"date\": date})\n",
    "    logger.success(f\"{dates[0]}到{dates[-1]}的数据全部写入完成了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def __update_factor(fac_key: str, fac_df: pd.DataFrame, token: str):\n",
    "    \"\"\"请勿使用此函数\"\"\"\n",
    "    ds_object = deeplake.load(\"hub://chenzongwei/factor\", token=token)\n",
    "    \"\"\"找到最近新增的部分，处理df数据的部分\"\"\"\n",
    "    old_dates = [i[0] for i in ds_object[fac_key].date.numpy().tolist()]\n",
    "    new_dates = [\n",
    "        i\n",
    "        for i in list(fac_df.index)\n",
    "        if i not in [pd.Timestamp(str(j)) for j in old_dates]\n",
    "    ]\n",
    "    fac_df = fac_df[fac_df.index.isin(new_dates)]\n",
    "    fac_df.index = fac_df.index.strftime(\"%Y%m%d\").astype(int)\n",
    "    fac_df.columns = fac_df.columns.str.slice(start=0, stop=-3).astype(int)\n",
    "    fac_df = fac_df.stack().reset_index()\n",
    "    fac_df.columns = [\"date\", \"code\", \"fac\"]\n",
    "    dates = fac_df.iloc[:, 0]\n",
    "    dates = sorted(list(set(dates)))\n",
    "    if len(dates) > 0:\n",
    "        \"\"\"每天更新写入\"\"\"\n",
    "        for date in tqdm.auto.tqdm(dates):\n",
    "            son = fac_df[fac_df.date == date].to_numpy()\n",
    "            ds_object[fac_key].append({\"value\": son, \"date\": date})\n",
    "        logger.success(f\"{dates[0]}到{dates[-1]}的数据全部更新完成了\")\n",
    "    else:\n",
    "        logger.warning(\"已经是最新的了，无需更新\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def show_all_factors_information(token: str) -> pd.DataFrame:\n",
    "    \"\"\"展示目前数据库内包含的所有因子数据的相关信息，包括：    \n",
    "    1. 数据键名：提取数据时需要使用的数据键名，即`read_factor`函数中的第一个参数`fac_key`，如：factor1    \n",
    "    2. 因子名称：研报中因子的名称，如：适度冒险因子    \n",
    "    3. 报告题目：发布该因子的研究报告的题目，如：成交量激增时刻蕴含的alpha信息——多因子选股系列研究之一    \n",
    "    4. 微信链接：该报告在微信公众号上的的宣传推文的链接    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    token : str\n",
    "        验证码\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        相关信息的表格\n",
    "    \"\"\"\n",
    "    ds_object = deeplake.load(\"hub://chenzongwei/factor\", token=token)\n",
    "    keys = [i[0] for i in ds_object.factors_list.fac_key[:].data()[\"text\"]]\n",
    "    names = [i[0] for i in ds_object.factors_list.fac_name[:].data()[\"text\"]]\n",
    "    reports = [i[0] for i in ds_object.factors_list.fac_report[:].data()[\"text\"]]\n",
    "    wechat_links = [\n",
    "        i[0] for i in ds_object.factors_list.fac_wechat_link[:].data()[\"text\"]\n",
    "    ]\n",
    "    info = pd.DataFrame(\n",
    "        {\"数据键名\": keys, \"因子名称\": names, \"报告题目\": reports, \"微信链接\": wechat_links}\n",
    "    )\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def read_factor(\n",
    "    fac_key: str,\n",
    "    token: str,\n",
    "    trade_date: int = None,\n",
    "    start_date: int = None,\n",
    "    end_date: int = None,\n",
    "    sql_like: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"通过表名，读取因子数据\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fac_key : str\n",
    "        表的名称\n",
    "    token : str\n",
    "        验证码\n",
    "    trade_date : int, optional\n",
    "        读取单日因子值，形如20230113，指定此参数时，start_date和end_date两个参数将失效, by default None\n",
    "    start_date : int, optional\n",
    "        读取因子值的起始日期，形如20130101, by default None\n",
    "    end_date : int, optional\n",
    "        读取因子值的终止日期，形如20221231, by default None\n",
    "    sql_like : bool, optional\n",
    "        返回的数据为形如sql中的长表，包括日期、股票代码、因子值三列, by default False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        因子值，index为每天的日期，columns为股票代码，values为因子值\n",
    "    \"\"\"\n",
    "\n",
    "    def wind_code(x):\n",
    "        if x[0] in [\"0\", \"3\"]:\n",
    "            return x + \".SZ\"\n",
    "        elif x[0] == \"6\":\n",
    "            return x + \".SH\"\n",
    "        elif x[0] == \"8\":\n",
    "            return x + \".BJ\"\n",
    "        else:\n",
    "            return x + \".UN\"\n",
    "\n",
    "    ds_object = deeplake.load(\"hub://chenzongwei/factor\", token=token)\n",
    "    \"\"\"找到起止日期的序号\"\"\"\n",
    "    all_dates = [i[0] for i in ds_object[fac_key].date.numpy().tolist()]\n",
    "    if trade_date is not None:\n",
    "        try:\n",
    "            trade_num = all_dates.index(trade_date)\n",
    "            fac_data = ds_object[fac_key].value[trade_num].numpy()\n",
    "        except Exception:\n",
    "            raise ValueError(f\"暂时没有{trade_date}这一天的因子值\")\n",
    "    else:\n",
    "        if start_date is not None:\n",
    "            try:\n",
    "                start_date = [i for i in all_dates if i <= start_date][-1]\n",
    "            except Exception:\n",
    "                raise ValueError(f\"暂时没有{start_date}及之后的因子值\")\n",
    "            start_num = all_dates.index(start_date)\n",
    "        else:\n",
    "            start_num = 0\n",
    "        if end_date is not None:\n",
    "            end_date = [i for i in all_dates if i >= end_date][0]\n",
    "            fac_data = np.vstack(\n",
    "                ds_object[fac_key]\n",
    "                .value[start_num : (all_dates.index(end_date) + 1)]\n",
    "                .numpy(aslist=True)\n",
    "            )\n",
    "        else:\n",
    "            fac_data = np.vstack(\n",
    "                ds_object[fac_key].value[start_num:].numpy(aslist=True)\n",
    "            )\n",
    "    \"\"\"整理数据\"\"\"\n",
    "    fac_data = pd.DataFrame(fac_data, columns=[\"date\", \"code\", fac_key])\n",
    "    fac_data.date = pd.to_datetime(\n",
    "        fac_data.date.astype(int).astype(str), format=\"%Y%m%d\"\n",
    "    )\n",
    "    fac_data.code = fac_data.code.astype(int).astype(str).str.zfill(6)\n",
    "    fac_data = fac_data.pivot(index=\"date\", columns=\"code\", values=fac_key)\n",
    "    fac_data.columns = [wind_code(i) for i in list(fac_data.columns)]\n",
    "    if sql_like:\n",
    "        fac_data = fac_data.stack().reset_index()\n",
    "        fac_data.columns = [\"date\", \"code\", fac_key]\n",
    "    return fac_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
